# AI Knowledgebase

## AI Agents Framework

1. [AG2 Reasoning Agents](https://ag2ai.github.io/ag2/blog/2024/12/02/ReasoningAgent2/)
2. [Bee Agent Framework](https://github.com/i-am-bee/bee-agent-framework)
3. [Codel](https://github.com/semanser/codel)
4. [Langchain](https://python.langchain.com/v0.1/docs/modules/agents/)
5. [Microsoft Autogen](https://microsoft.github.io/autogen/0.2/)
6. [OpenAI Swarm](https://github.com/openai/swarm)
7. [SuperAGI](https://github.com/TransformerOptimus/SuperAGI)
8. [ai16z/eliza](https://ai16z.github.io/eliza/)

## OpenSource LLM Models
### Audio Models
1. A Fairytaler that Fakes Fluent and Faithful Speech with Flow Matching [F5-TTS](https://github.com/SWivid/F5-TTS)
2. Moshi: a speech-text foundation model for real time dialogue [Moshi](https://github.com/kyutai-labs/moshi)

## AI Coding Agents (Tested)
### Open Source/Free
1. Cline: Autonomous coding agent right in your IDE, capable of creating/editing files, executing commands, using the browser, and more with your permission every step of the way. [Cline](https://github.com/cline/cline)

### Paid(Free Trial/Limited Queries)
1. Windsurf: The first agentic IDE, and then some. The Windsurf Editor is where the work of developers and AI truly flow together. [Windsurf](https://codeium.com/windsurf)

## OpenSource Similar to Perplexity 
1. [Perplexica](https://github.com/ItzCrazyKns/Perplexica)
2. [Scira](https://github.com/zaidmukaddam/scira)

## OpenSource Models creating AI Avatar
1. Towards Striking, Simplified, and Semi-Body Human Animation [EchoMimicV2](https://github.com/antgroup/echomimic_v2)
2. [Fooocus](https://github.com/lllyasviel/Fooocus)
3. Learning Realistic 3D Motion Coefficients for Stylized Audio-Driven Single Image Talking Face Animation [SadTalker](https://github.com/OpenTalker/SadTalker)
4. Efficient Portrait Animation with Stitching and Retargeting Control
 [LivePortrait](https://github.com/KwaiVGI/LivePortrait)
5. Hierarchical Audio-Driven Visual Synthesis for Portrait Image Animation [hallo](https://github.com/fudan-generative-vision/hallo)
6. Latent-space synchronization for open-domain realistic talking-face generation [LatentSync](https://github.com/bytedance/LatentSync)
7. This node provides lip-sync capabilities in ComfyUI using ByteDance's LatentSync model. It allows you to synchronize video lips with audio input. [ComfyUI-LatentSyncWrapper](https://github.com/ShmuelRonen/ComfyUI-LatentSyncWrapper)
